{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def pad_input_matrix(X, pad: int, padding_value: int = 0):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image\n",
    "\n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "\n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C) # m is omitted for now\n",
    "    \"\"\"\n",
    "    X_pad = np.pad(X, pad_width=((0, 0), (pad, pad), (pad, pad)),\n",
    "                   mode='constant', constant_values=(padding_value, padding_value))\n",
    "    # X_pad = np.pad(X, ((0,0),(pad,pad),(pad,pad),(0,0)))\n",
    "\n",
    "    return X_pad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ConvolutionalLayer:\n",
    "    # number of output channel = filter counts\n",
    "    def __init__(self, input_shape: (int, int, int), number_of_output_channel: int, filter_dimension: int,\n",
    "                 stride: int, padding: int):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.number_of_output_channel = number_of_output_channel\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "\n",
    "        self.output_shape = (number_of_output_channel, input_height - filter_dimension + 1, input_width\n",
    "                             - filter_dimension + 1)\n",
    "\n",
    "        self.filters_shape = (number_of_output_channel, input_depth, filter_dimension, filter_dimension)\n",
    "        self.filters = np.random.randn(*self.filters_shape)\n",
    "\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "\n",
    "    def convolution_single_step(input_slice, filter_mat):\n",
    "        \"\"\"\n",
    "        Apply one filter defined by parameters weight on a single slice (a_slice_prev) of the output activation\n",
    "        of the previous layer.\n",
    "\n",
    "        Arguments:\n",
    "        a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "        weight -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "        bias -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "\n",
    "        Returns:\n",
    "        Z -- a scalar value, the result of convolving the sliding window (weight, bias) on a slice x of the input data\n",
    "        \"\"\"\n",
    "\n",
    "        #(≈ 3 lines of code)\n",
    "        # Element-wise product between a_slice_prev and weight. Do not add the bias yet.\n",
    "        s = np.multiply(a_slice_prev, weight)\n",
    "        # Sum over all entries of the volume s.\n",
    "        Z = np.sum(s)\n",
    "        # Add bias to Z. Cast bias to a float() so that Z results in a scalar value.\n",
    "        bias = np.squeeze(bias)\n",
    "        Z = Z + bias\n",
    "\n",
    "        return Z\n",
    "\n",
    "\n",
    "    def conv_forward(self, A_prev, W, b):\n",
    "        \"\"\"\n",
    "        Implements the forward propagation for a convolution function\n",
    "\n",
    "        Arguments:\n",
    "        A_prev -- output activations of the previous layer,\n",
    "            numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "        b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "        hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "\n",
    "        Returns:\n",
    "        Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "        cache -- cache of values needed for the conv_backward() function\n",
    "        \"\"\"\n",
    "\n",
    "        # Retrieve dimensions from A_prev's shape (≈1 line)\n",
    "        (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "\n",
    "        # Retrieve dimensions from W's shape (≈1 line)\n",
    "        (f, f, n_C_prev, n_C) = W.shape\n",
    "\n",
    "        # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "        # stride = hparameters[\"stride\"]\n",
    "        # pad = hparameters[\"pad\"]\n",
    "\n",
    "        # Compute the dimensions of the CONV output volume using the formula given above.\n",
    "        # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n",
    "        n_H = int((n_H_prev + 2*self.padding - f)/self.stride) + 1\n",
    "        n_W = int((n_W_prev + 2*self.padding - f)/self.stride) + 1\n",
    "\n",
    "        # Initialize the output volume Z with zeros. (≈1 line)\n",
    "        Z = np.zeros((m, n_H, n_W, n_C))\n",
    "\n",
    "        # Create A_prev_pad by padding A_prev\n",
    "        A_prev_pad = zero_pad(A_prev, self.padding)\n",
    "\n",
    "        for i in range(m):               # loop over the batch of training examples\n",
    "            a_prev_pad = A_prev_pad[i]          # Select ith training example's padded activation\n",
    "            for h in range(n_H):           # loop over vertical axis of the output volume\n",
    "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "                vert_start = self.stride * h\n",
    "                vert_end = vert_start  + f\n",
    "\n",
    "                for w in range(n_W):       # loop over horizontal axis of the output volume\n",
    "                    # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
    "                    horiz_start = self.stride * w\n",
    "                    horiz_end = horiz_start + f\n",
    "\n",
    "                    for c in range(n_C):   # loop over channels (= #filters) of the output volume\n",
    "\n",
    "                        # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                        a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "\n",
    "                        # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
    "                        weights = W[:, :, :, c]\n",
    "                        biases  = b[:, :, :, c]\n",
    "                        Z[i, h, w, c] = self.convolution_single_step(a_slice_prev, weights, biases)\n",
    "\n",
    "        # Save information in \"cache\" for the backprop\n",
    "        cache = (A_prev, W, b, hparameters)\n",
    "\n",
    "        return Z, cache\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.62434536 -0.61175641]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(2, 2)\n",
    "s, _ = x.shape\n",
    "print(x[0])\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "temp = np.floor(3.7)\n",
    "print(temp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0]\n",
      " [ 0  1  2  0]\n",
      " [ 0  3 40  0]\n",
      " [ 0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "a = [[1, 2], [3, 40]]\n",
    "a = np.pad(a, pad_width=(1, 1)  mode='constant', constant_values=(0, 0))\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.91797604 -0.85183742]\n",
      "  [ 0.09075857  1.16220247]]\n",
      "\n",
      " [[ 0.32178247  1.34131783]\n",
      "  [ 0.14167518  1.73738467]]\n",
      "\n",
      " [[ 0.37576878  1.47825568]\n",
      "  [-2.08016719 -0.45342757]]]\n",
      "[[-0.91797604]\n",
      " [-0.85183742]\n",
      " [ 0.09075857]\n",
      " [ 1.16220247]\n",
      " [ 0.32178247]\n",
      " [ 1.34131783]\n",
      " [ 0.14167518]\n",
      " [ 1.73738467]\n",
      " [ 0.37576878]\n",
      " [ 1.47825568]\n",
      " [-2.08016719]\n",
      " [-0.45342757]]\n",
      "(12, 1)\n"
     ]
    }
   ],
   "source": [
    "def flatten_matrix(input):\n",
    "    return input.flatten().reshape(-1, 1)\n",
    "\n",
    "x = np.random.randn(3, 2, 2)\n",
    "y = flatten_matrix(x)\n",
    "print(x)\n",
    "print(y)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4]\n",
      " [5 1]]\n",
      "[[2 4]\n",
      " [5 3]]\n",
      "[[ 4 16]\n",
      " [25  3]]\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.random.randint(low = 1, high = 8, size=(2, 2))\n",
    "y = np.random.randint(low = 1, high = 8, size=(2, 2))\n",
    "print(x)\n",
    "print(y)\n",
    "print(np.multiply(x, y))\n",
    "print(np.sum(np.multiply(x, y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 9 9]\n",
      " [9 1 8]\n",
      " [3 1 8]]\n",
      "[[8 1 3]\n",
      " [8 1 9]\n",
      " [9 9 8]]\n"
     ]
    }
   ],
   "source": [
    "kernel = np.random.randint(low=1, high=10, size=(3,3))\n",
    "print(kernel)\n",
    "kernel = np.flipud(np.fliplr(kernel))\n",
    "print(kernel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def file_read(file_path: str):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    lines = [line.split() for line in lines]\n",
    "    lines = [[int(x) if idx != 0 else x for idx, x in enumerate(line)] for line in lines]\n",
    "\n",
    "    '''\n",
    "    *********************************** INPUT FORMAT *********************************************\n",
    "    Conv: the number of output channels, filter dimension, stride, padding.\n",
    "    ReLU: Activation layer.\n",
    "    Pool: filter dimension, stride.\n",
    "    FC: output dimension.\n",
    "    Flattening layer: it will convert a (series of) convolutional filter maps to a column vector.\n",
    "    Softmax: it will convert final layer projections to normalized probabilities.\n",
    "    '''\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def pad_input_2d_mat(X, pad: int, padding_value: int = 0):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image\n",
    "\n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "\n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C) # m is omitted for now\n",
    "    \"\"\"\n",
    "    X_pad = np.pad(X, pad_width=((pad, pad), (pad, pad)),\n",
    "                   mode='constant', constant_values=(padding_value, padding_value))\n",
    "    # X_pad = np.pad(X, ((0,0),(pad,pad),(pad,pad),(0,0)))\n",
    "\n",
    "    return X_pad\n",
    "\n",
    "\n",
    "def cross_correlation2d(input_mat, filter_mat, stride, padding, result_shape):\n",
    "    filter_dimension, _ = filter_mat.shape\n",
    "    _, result_height, result_width = result_shape\n",
    "\n",
    "    result = np.zeros((result_height, result_width), dtype=float)\n",
    "\n",
    "    if padding != 0:\n",
    "        pad_input = pad_input_2d_mat(input_mat, pad=padding)\n",
    "    else:\n",
    "        pad_input = input_mat\n",
    "\n",
    "    for h in range(result_height):  # loop over vertical axis of the output volume\n",
    "        # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "        vertical_start = stride * h\n",
    "        vertical_end = vertical_start + filter_dimension\n",
    "\n",
    "        for w in range(result_width):  # loop over horizontal axis of the output volume\n",
    "            # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
    "            horizontal_start = stride * w\n",
    "            horizontal_end = horizontal_start + filter_dimension\n",
    "\n",
    "            input_slice = pad_input[vertical_start:vertical_end, horizontal_start:horizontal_end]\n",
    "            result[h, w] = np.sum(np.multiply(input_slice, filter_mat))\n",
    "            # print(result[h, w])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def convolution2d(input_mat, filter_mat, stride, padding, result_shape):\n",
    "    # Flip the filter\n",
    "    rotated_filter = np.flipud(np.fliplr(filter_mat))\n",
    "\n",
    "    return cross_correlation2d(input_mat, rotated_filter, stride, padding, result_shape)\n",
    "\n",
    "\n",
    "def flatten_matrix(input_data):\n",
    "    return input_data.flatten().reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "x = np.random.randn(100, 5, 4, 4)\n",
    "print(x.shape[1:])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CIFAR dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load daatset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(60000,)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(y_train.shape)\n",
    "print(y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_mnist_data(x, y):\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float64\") / 255\n",
    "    # y = np_utils.to_categorical(y)\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 153600000 into shape (50000,1,28,28)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [65]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m x_train, y_train \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocess_mnist_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m x_test, y_test \u001B[38;5;241m=\u001B[39m preprocess_mnist_data(x_test, y_test)\n",
      "Input \u001B[0;32mIn [64]\u001B[0m, in \u001B[0;36mpreprocess_mnist_data\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess_mnist_data\u001B[39m(x, y):\n\u001B[0;32m----> 5\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat64\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255\u001B[39m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# y = np_utils.to_categorical(y)\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: cannot reshape array of size 153600000 into shape (50000,1,28,28)"
     ]
    }
   ],
   "source": [
    "x_train, y_train = preprocess_mnist_data(x_train, y_train)\n",
    "x_test, y_test = preprocess_mnist_data(x_test, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(60000, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "set_printoptions() got multiple values for argument 'precision'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [43]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(x_train\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_train\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_printoptions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprecision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mTypeError\u001B[0m: set_printoptions() got multiple values for argument 'precision'"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR10 dataset load"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "new_x_train = np.transpose(x_train, (0, 3, 1, 2))\n",
    "new_x_test = np.transpose(x_test, (0, 3, 1, 2))\n",
    "\n",
    "print(new_x_train.shape)\n",
    "print(new_x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 59,  43,  50, ..., 158, 152, 148],\n        [ 16,   0,  18, ..., 123, 119, 122],\n        [ 25,  16,  49, ..., 118, 120, 109],\n        ...,\n        [208, 201, 198, ..., 160,  56,  53],\n        [180, 173, 186, ..., 184,  97,  83],\n        [177, 168, 179, ..., 216, 151, 123]],\n\n       [[ 62,  46,  48, ..., 132, 125, 124],\n        [ 20,   0,   8, ...,  88,  83,  87],\n        [ 24,   7,  27, ...,  84,  84,  73],\n        ...,\n        [170, 153, 161, ..., 133,  31,  34],\n        [139, 123, 144, ..., 148,  62,  53],\n        [144, 129, 142, ..., 184, 118,  92]],\n\n       [[ 63,  45,  43, ..., 108, 102, 103],\n        [ 20,   0,   0, ...,  55,  50,  57],\n        [ 21,   0,   8, ...,  50,  50,  42],\n        ...,\n        [ 96,  34,  26, ...,  70,   7,  20],\n        [ 96,  42,  30, ...,  94,  34,  34],\n        [116,  94,  87, ..., 140,  84,  72]]], dtype=uint8)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [47]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# print(ara)\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# print(ara1)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m s \u001B[38;5;241m=\u001B[39m f_size[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "f_size = (1,2,3,4)\n",
    "print(*f_size)\n",
    "ara = np.random.randn(*f_size)\n",
    "ara1 = np.random.sample(f_size)\n",
    "\n",
    "# print(ara)\n",
    "# print(ara1)\n",
    "s = f_size[1:]\n",
    "print(s)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "def preprocess_mnist_data(x, y):\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float64\") / 255\n",
    "    y = y.reshape(-1, 1)\n",
    "    y = np_utils.to_categorical(y) # confusion\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def preprocess_cifar10_data(x, y): # dimension (60k, 32, 32, 3)\n",
    "    x = np.transpose(x, (0, 3, 1, 2)) # changed dimension (60k, 3, 32, 32)\n",
    "    x = x.astype(\"float64\") / 255\n",
    "    y = np_utils.to_categorical(y) # confusion\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def mnist_dataset_load_and_preprocess():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, y_train = preprocess_mnist_data(x_train, y_train)\n",
    "    x_test, y_test = preprocess_mnist_data(x_test, y_test)\n",
    "\n",
    "    test_len = int(len(x_test)/2)\n",
    "\n",
    "    x_test_new = x_test[0:test_len]\n",
    "    y_test_new = y_test[0:test_len]\n",
    "\n",
    "    x_valid = x_test[test_len:]\n",
    "    y_valid = y_test[test_len:]\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid, x_test_new, y_test_new\n",
    "\n",
    "\n",
    "def cifar10_dataset_load_and_preprocess():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()  # dimension (60k, 32, 32, 3)\n",
    "    x_train, y_train = preprocess_cifar10_data(x_train, y_train)\n",
    "    x_test, y_test = preprocess_cifar10_data(x_test, y_test)\n",
    "\n",
    "    test_len = int(len(x_test)/2)\n",
    "\n",
    "    x_test_new = x_test[0:test_len]\n",
    "    y_test_new = y_test[0:test_len]\n",
    "\n",
    "    x_valid = x_test[test_len:]\n",
    "    y_valid = y_test[test_len:]\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid, x_test_new, y_test_new"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test = mnist_dataset_load_and_preprocess()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = cifar10_dataset_load_and_preprocess()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1, 28, 28)\n",
      "(5000, 10)\n",
      "(60000, 1, 28, 28)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 32, 32)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [-1  0]]\n",
      "[[ 0 -1]\n",
      " [ 2  1]]\n"
     ]
    }
   ],
   "source": [
    "kernel = np.array([[1, 2], [-1, 0]])\n",
    "print(kernel)\n",
    "kernel = np.flipud(np.fliplr(kernel))\n",
    "print(kernel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### signal convolution check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def cross_correlation2d(input_mat, filter_mat, stride, padding, result_shape):\n",
    "    filter_dimension = filter_mat.shape[0]\n",
    "    result_height, result_width = result_shape\n",
    "\n",
    "    result = np.zeros((result_height, result_width), dtype='float64')\n",
    "\n",
    "    if padding > 0:\n",
    "        pad_input = pad_input_2d_mat(input_mat, pad=padding)\n",
    "    else:\n",
    "        pad_input = input_mat\n",
    "\n",
    "    for h in range(result_height):  # loop over vertical axis of the output volume\n",
    "        # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "        vertical_start = stride * h\n",
    "        vertical_end = vertical_start + filter_dimension\n",
    "\n",
    "        for w in range(result_width):  # loop over horizontal axis of the output volume\n",
    "            # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
    "            horizontal_start = stride * w\n",
    "            horizontal_end = horizontal_start + filter_dimension\n",
    "\n",
    "            input_slice = pad_input[vertical_start:vertical_end, horizontal_start:horizontal_end]\n",
    "            result[h, w] = np.sum(np.multiply(input_slice, filter_mat))\n",
    "            # print(result[h, w])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def convolution2d(input_mat, filter_mat, stride, padding, result_shape):\n",
    "    # Flip the filter\n",
    "    rotated_filter = np.flipud(np.fliplr(filter_mat))\n",
    "\n",
    "    return cross_correlation2d(input_mat, rotated_filter, stride, padding, result_shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 6 2]\n",
      " [5 3 1]\n",
      " [7 0 4]]\n",
      "[[ 1  2]\n",
      " [-1  0]]\n",
      "[[8 7]\n",
      " [4 5]]\n",
      "[[8.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import convolve2d, correlate2d\n",
    "w = np.array([[1, 6, 2], [5, 3, 1], [7, 0, 4]])\n",
    "print(w)\n",
    "kernel = np.array([[1, 2], [-1, 0]])\n",
    "print(kernel)\n",
    "out1 = correlate2d(w, kernel, mode='valid')\n",
    "print(out1)\n",
    "out2 = cross_correlation2d(w, kernel, 2, 0, (2,2))\n",
    "print(out2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[37 34 24]\n",
      "   [47 17 24]]\n",
      "\n",
      "  [[52 54 68]\n",
      "   [78 48 56]]\n",
      "\n",
      "  [[67 62 47]\n",
      "   [79 28 46]]]\n",
      "\n",
      "\n",
      " [[[67 63 53]\n",
      "   [78 30 50]]\n",
      "\n",
      "  [[43 46 60]\n",
      "   [89 59 48]]\n",
      "\n",
      "  [[59 57 51]\n",
      "   [96 48 46]]]]\n",
      "[[[37 34 24]\n",
      "  [52 54 68]\n",
      "  [67 62 47]]\n",
      "\n",
      " [[78 30 50]\n",
      "  [89 59 48]\n",
      "  [96 48 46]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(low = 1, high = 8, size=(2, 3, 3))\n",
    "y = np.random.randint(low = 1, high = 8, size=(2, 3, 3))\n",
    "print(np.dot(x, y))\n",
    "print(np.matmul(x, y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5]\n",
      " [6]\n",
      " [4]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [6]\n",
      " [7]\n",
      " [5]]\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "hello\n",
      "3\n",
      "2\n",
      "1\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.randint(low = 1, high = 8, size=(10, 1))\n",
    "print(x)\n",
    "print(len(x))\n",
    "\n",
    "a = [1,2,3]\n",
    "\n",
    "for i in a:\n",
    "    print(i)\n",
    "print('hello')\n",
    "for i in reversed(a):\n",
    "    print(i)\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.]\n",
      " [456.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  0.]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.zeros((10,1))\n",
    "arr[1] = [456]\n",
    "print(arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eefef\n"
     ]
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        self.a = 6\n",
    "        self.g='eefef'\n",
    "\n",
    "t = test()\n",
    "print(t.g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def pad_input_2d_mat(X, pad: int, padding_value: int = 0):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image\n",
    "\n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "\n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C) # m is omitted for now\n",
    "    \"\"\"\n",
    "    X_pad = np.pad(X, pad_width=((pad, pad), (pad, pad)),\n",
    "                   mode='constant', constant_values=(padding_value, padding_value))\n",
    "    # X_pad = np.pad(X, ((0,0),(pad,pad),(pad,pad),(0,0)))\n",
    "\n",
    "    return X_pad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def relu_derivative(x):\n",
    "    # x[x < 0] = 0.01 * x  # leaky ReLU\n",
    "    # x[x >= 0] = 1\n",
    "    x = np.where(x> 0, x, x * 0.01)\n",
    "    # new_window = (specific_window == np.max(specific_window))\n",
    "    return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10, 1)\n",
      "[[[ 5]\n",
      "  [ 4]\n",
      "  [ 4]\n",
      "  [ 8]\n",
      "  [ 7]\n",
      "  [ 8]\n",
      "  [11]\n",
      "  [ 9]\n",
      "  [ 7]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 6]\n",
      "  [11]\n",
      "  [ 0]\n",
      "  [ 8]\n",
      "  [ 2]\n",
      "  [ 2]\n",
      "  [ 2]\n",
      "  [ 0]\n",
      "  [ 9]\n",
      "  [ 7]]\n",
      "\n",
      " [[ 2]\n",
      "  [ 0]\n",
      "  [ 3]\n",
      "  [ 9]\n",
      "  [ 3]\n",
      "  [ 2]\n",
      "  [ 7]\n",
      "  [11]\n",
      "  [11]\n",
      "  [ 8]]\n",
      "\n",
      " [[ 1]\n",
      "  [ 4]\n",
      "  [ 7]\n",
      "  [ 6]\n",
      "  [ 1]\n",
      "  [ 5]\n",
      "  [ 5]\n",
      "  [ 3]\n",
      "  [ 0]\n",
      "  [ 6]]\n",
      "\n",
      " [[ 5]\n",
      "  [ 6]\n",
      "  [ 4]\n",
      "  [ 2]\n",
      "  [ 0]\n",
      "  [ 7]\n",
      "  [11]\n",
      "  [ 8]\n",
      "  [ 1]\n",
      "  [ 8]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.randint(low=0, high=12, size=(5,10))\n",
    "s = x.shape + (1, )\n",
    "\n",
    "print(s)\n",
    "x = np.reshape(x, s)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}